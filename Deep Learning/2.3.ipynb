{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71276cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.), tensor(1.), tensor(1.5000), tensor(9.))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor(3.0)\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "x+y,x-y,x/y,x**y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a4fd4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b8472f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa916c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fde3629f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a3287f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15],\n",
       "        [16, 17, 18, 19]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20).reshape(5,4)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2b11560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  4,  8, 12, 16],\n",
       "        [ 1,  5,  9, 13, 17],\n",
       "        [ 2,  6, 10, 14, 18],\n",
       "        [ 3,  7, 11, 15, 19]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ffc48df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [2, 0, 4],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.tensor([[1,2,3],[2,0,4],[3,4,5]])\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60d06692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B == B.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "490d1b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(24).reshape(2,3,4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2990d183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([[ 0.,  2.,  4.,  6.],\n",
       "         [ 8., 10., 12., 14.],\n",
       "         [16., 18., 20., 22.],\n",
       "         [24., 26., 28., 30.],\n",
       "         [32., 34., 36., 38.]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20,dtype=torch.float32).reshape(5,4)\n",
    "B = A.clone()\n",
    "A,A+B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a95e963f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   1.,   4.,   9.],\n",
       "        [ 16.,  25.,  36.,  49.],\n",
       "        [ 64.,  81., 100., 121.],\n",
       "        [144., 169., 196., 225.],\n",
       "        [256., 289., 324., 361.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A*B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "768f47f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2,  3,  4,  5],\n",
       "          [ 6,  7,  8,  9],\n",
       "          [10, 11, 12, 13]],\n",
       " \n",
       "         [[14, 15, 16, 17],\n",
       "          [18, 19, 20, 21],\n",
       "          [22, 23, 24, 25]]]),\n",
       " torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 2\n",
    "\n",
    "X = torch.arange(24).reshape(2,3,4)\n",
    "a+X,(a*X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d8b34ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor(6.))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4,dtype=torch.float32)\n",
    "x,x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bcf1ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 4]), tensor(190.))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape,A.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86a841e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([40., 45., 50., 55.]), torch.Size([4]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_sum_axis0 = A.sum(axis=0)\n",
    "A_sum_axis0,A_sum_axis0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70ff3279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 6., 22., 38., 54., 70.]), torch.Size([5]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_sum_axis1 = A.sum(axis=1)\n",
    "A_sum_axis1,A_sum_axis1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "351fcb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(190.)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(axis=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8f7d7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9.5000), tensor(9.5000))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(),A.sum()/A.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e411e2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 8.,  9., 10., 11.]), tensor([ 8.,  9., 10., 11.]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(axis=0),A.sum(axis=0)/A.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b007d0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.],\n",
       "        [22.],\n",
       "        [38.],\n",
       "        [54.],\n",
       "        [70.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_A = A.sum(axis=1,keepdims=True)\n",
    "sum_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1f492b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1667, 0.3333, 0.5000],\n",
       "        [0.1818, 0.2273, 0.2727, 0.3182],\n",
       "        [0.2105, 0.2368, 0.2632, 0.2895],\n",
       "        [0.2222, 0.2407, 0.2593, 0.2778],\n",
       "        [0.2286, 0.2429, 0.2571, 0.2714]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A/sum_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7fa241e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  6.,  8., 10.],\n",
       "        [12., 15., 18., 21.],\n",
       "        [24., 28., 32., 36.],\n",
       "        [40., 45., 50., 55.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.cumsum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7c74dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.ones(4,dtype = torch.float32)\n",
    "x,y,torch.dot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f9700331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x * y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5f641cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 4]), torch.Size([4]), tensor([ 14.,  38.,  62.,  86., 110.]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape,x.shape,torch.mv(A,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e25d7175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.,  6.,  6.],\n",
       "        [22., 22., 22.],\n",
       "        [38., 38., 38.],\n",
       "        [54., 54., 54.],\n",
       "        [70., 70., 70.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B=torch.ones(4,3)\n",
    "torch.mm(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40283f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor([3.0,-4.0])\n",
    "torch.norm(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fe288252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(u).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1fcfa278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(torch.ones(4,9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1018993c",
   "metadata": {},
   "source": [
    "# 2.3线性代数\n",
    "## 一、基本数学对象\n",
    "| 对象       | 数学定义与表示                | 代码实现（PyTorch）          | 核心属性                          |\n",
    "|------------|-----------------------------|-----------------------------|-----------------------------------|\n",
    "| 标量（Scalar） | 单个实数值，记为小写字母（如$x$），$x \\in \\mathbb{R}$ | `x = torch.tensor(3.0)`     | 零阶张量，无轴，仅含一个元素      |\n",
    "| 向量（Vector） | 标量组成的列表，记为粗体小写字母（如$\\mathbf{x}$），$\\mathbf{x} \\in \\mathbb{R}^n$（$n$为长度） | `x = torch.arange(4)`       | 一阶张量，单轴，形状为$[n]$；默认列向量 |\n",
    "| 矩阵（Matrix） | 向量组成的二维表格，记为粗体大写字母（如$\\mathbf{A}$），$\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$（$m$行$n$列） | `A = torch.arange(20).reshape(5,4)` | 二阶张量，双轴（行轴0、列轴1），形状为$[m,n]$ |\n",
    "| 张量（Tensor） | 任意维度的数组，记为特殊字体大写字母（如$\\mathsf{X}$），$k$阶张量有$k$个轴 | `X = torch.arange(24).reshape(2,3,4)` | 高阶张量（轴数$\\geq3$），形状为$[d_1,d_2,...,d_k]$ |\n",
    "\n",
    "### 关键概念区分\n",
    "- **维度（dimension）**：  \n",
    "  - 向量/轴的维度：指向量/轴的长度（元素个数）；  \n",
    "  - 张量的维度：指张量的轴数（如矩阵是2维张量，对应2个轴）。\n",
    "- **形状（shape）**：张量沿每个轴的长度组成的元组（如3阶张量形状$[2,3,4]$表示轴0长2、轴1长3、轴2长4）。\n",
    "\n",
    "## 二、核心运算（含数学定义+代码实现）\n",
    "### 1. 按元素运算\n",
    "- 适用场景：相同形状的张量，运算作用于对应位置元素；标量与张量运算时，标量与每个元素作用。\n",
    "- 常用运算：\n",
    "  - 加减乘除：`x + y`、`x - y`、`x * y`、`x / y`（标量/张量通用）；\n",
    "  - 指数：`x ** y`；\n",
    "  - Hadamard积（矩阵按元素乘法）：$\\mathbf{A} \\odot \\mathbf{B}$，代码`A * B`（注意区别于矩阵乘法）。\n",
    "\n",
    "### 2. 点积（Dot Product）\n",
    "- 数学定义：$\\mathbf{x}^\\top \\mathbf{y} = \\sum_{i=1}^d x_i y_i$（$\\mathbf{x},\\mathbf{y} \\in \\mathbb{R}^d$，结果为标量）；\n",
    "- 代码实现：`torch.dot(x, y)` 或 `torch.sum(x * y)`；\n",
    "- 用途：加权和、规范化后向量的夹角余弦计算。\n",
    "\n",
    "### 3. 矩阵-向量积\n",
    "- 数学定义：$\\mathbf{A}\\mathbf{x} \\in \\mathbb{R}^m$（$\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$，$\\mathbf{x} \\in \\mathbb{R}^n$），第$i$个元素为$\\mathbf{a}_i^\\top \\mathbf{x}$（$\\mathbf{a}_i$是$\\mathbf{A}$的第$i$行向量）；\n",
    "- 代码实现：`torch.mv(A, x)`（约束：$\\mathbf{A}$的列数 = $\\mathbf{x}$的长度）；\n",
    "- 用途：线性变换（如神经网络全连接层前向计算）。\n",
    "\n",
    "### 4. 矩阵-矩阵乘法\n",
    "- 数学定义：$\\mathbf{C} = \\mathbf{A}\\mathbf{B} \\in \\mathbb{R}^{n \\times m}$（$\\mathbf{A} \\in \\mathbb{R}^{n \\times k}$，$\\mathbf{B} \\in \\mathbb{R}^{k \\times m}$），元素$c_{ij} = \\mathbf{a}_i^\\top \\mathbf{b}_j$（$\\mathbf{a}_i$是$\\mathbf{A}$第$i$行，$\\mathbf{b}_j$是$\\mathbf{B}$第$j$列）；\n",
    "- 代码实现：`torch.mm(A, B)`（约束：$\\mathbf{A}$的列数 = $\\mathbf{B}$的行数）；\n",
    "- 本质：$m$次矩阵-向量积的结果拼接（$\\mathbf{B}$每列对应一次矩阵-向量积）。\n",
    "\n",
    "### 5. 转置（Transpose）\n",
    "- 数学定义：$\\mathbf{A}^\\top$（$\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$），形状变为$[n \\times m]$，元素$a_{ij}^\\top = a_{ji}$；\n",
    "- 代码实现：`A.T`；\n",
    "- 性质：$(\\mathbf{A}^\\top)^\\top = \\mathbf{A}$、$\\mathbf{A}^\\top + \\mathbf{B}^\\top = (\\mathbf{A} + \\mathbf{B})^\\top$；\n",
    "- 特殊矩阵：对称矩阵$\\mathbf{A} = \\mathbf{A}^\\top$。\n",
    "\n",
    "## 三、降维与累积操作\n",
    "### 1. 求和（sum）与均值（mean）\n",
    "- 全量降维：`A.sum()`（所有元素求和）、`A.mean()`（所有元素均值，等价于`A.sum() / A.numel()`，`numel()`返回元素总数）；\n",
    "- 指定轴降维：`A.sum(axis=0)`（沿行轴求和，消去轴0）、`A.mean(axis=1)`（沿列轴求均值，消去轴1）；\n",
    "- 多轴降维：`A.sum(axis=[0,1])`（沿轴0和轴1同时求和，等价于全量求和）。\n",
    "\n",
    "### 2. 非降维求和（keepdims=True）\n",
    "- 作用：保持张量轴数不变，便于后续广播运算（如矩阵与每行求和结果的逐元素除法）；\n",
    "- 代码示例：`sum_A = A.sum(axis=1, keepdims=True)`（形状仍为$[5,1]$，而非$[5]$），后续可执行`A / sum_A`。\n",
    "\n",
    "### 3. 累积求和（cumsum）\n",
    "- 数学定义：沿指定轴计算元素的累积和，不改变张量形状；\n",
    "- 代码实现：`A.cumsum(axis=0)`（沿行轴累积求和，第$i$行是前$i$行的和）。\n",
    "\n",
    "## 四、范数（Norm）\n",
    "范数是向量/矩阵“大小”的度量，满足4个性质：$f(\\alpha\\mathbf{x})=|\\alpha|f(\\mathbf{x})$、$f(\\mathbf{x}+\\mathbf{y}) \\leq f(\\mathbf{x})+f(\\mathbf{y})$、$f(\\mathbf{x}) \\geq 0$、$f(\\mathbf{x})=0 \\iff \\mathbf{x}=\\mathbf{0}$。\n",
    "\n",
    "| 范数类型       | 数学定义                                  | 代码实现                  | 特点与用途                          |\n",
    "|----------------|-------------------------------------------|---------------------------|-----------------------------------|\n",
    "| $L_2$范数      | $\\|\\|\\mathbf{x}\\|\\|_2 = \\sqrt{\\sum_{i=1}^n x_i^2}$ | `torch.norm(u)`           | 欧几里得距离，最常用；省略下标时$\\|\\|\\mathbf{x}\\|\\| = \\|\\|\\mathbf{x}\\|\\|_2$ |\n",
    "| $L_1$范数      | $\\|\\|\\mathbf{x}\\|\\|_1 = \\sum_{i=1}^n |x_i|$ | `torch.abs(u).sum()`      | 抗异常值影响，常用于稀疏性约束      |\n",
    "| Frobenius范数  | $\\|\\|\\mathbf{X}\\|\\|_F = \\sqrt{\\sum_{i=1}^m \\sum_{j=1}^n x_{ij}^2}$ | `torch.norm(matrix)`      | 矩阵的“$L_2$范数”，满足向量范数所有性质 |\n",
    "\n",
    "## 五、深度学习中的应用场景\n",
    "1. **数据表示**：标量（单个属性）、向量（样本特征）、矩阵（样本集合）、张量（图像/视频等多维数据）；\n",
    "2. **模型计算**：矩阵-向量积（全连接层）、矩阵-矩阵乘法（批量样本计算）、Hadamard积（元素级权重调整）；\n",
    "3. **优化目标**：范数最小化（如$L_2$正则化抑制过拟合、$L_1$正则化诱导稀疏性）、距离度量（预测值与真实值的范数差）。\n",
    "\n",
    "## 六、核心小结\n",
    "1. 线性代数对象的泛化关系：标量（0阶）→ 向量（1阶）→ 矩阵（2阶）→ 张量（高阶）；\n",
    "2. 运算核心约束：矩阵-向量积要求“矩阵列数=向量长度”，矩阵-矩阵乘法要求“前矩阵列数=后矩阵行数”；\n",
    "3. 降维操作关键：`axis`指定降维方向，`keepdims=True`保留轴数以支持广播；\n",
    "4. 范数核心用途：度量大小、约束模型参数、构建优化目标。\n",
    "\n",
    "## 练习关键思路提示\n",
    "1. 转置性质证明：从元素定义出发，$(\\mathbf{A}^\\top)^\\top$的元素为$(a_{ji})^\\top = a_{ij}$，与$\\mathbf{A}$一致；\n",
    "2. 转置和的性质：$(\\mathbf{A}+\\mathbf{B})^\\top$的元素为$a_{ji}+b_{ji}$，等于$\\mathbf{A}^\\top + \\mathbf{B}^\\top$的元素；\n",
    "3. 对称矩阵判断：$(\\mathbf{A}+\\mathbf{A}^\\top)^\\top = \\mathbf{A}^\\top + (\\mathbf{A}^\\top)^\\top = \\mathbf{A}^\\top + \\mathbf{A}$，故必对称；\n",
    "4. `len(X)`（$X$形状$[2,3,4]$）：返回轴0的长度（2），`len(X)`始终对应轴0的长度；\n",
    "5. `A/A.sum(axis=1)`报错：`sum(axis=1)`后形状为$[5]$，与$\\mathbf{A}$（$[5,4]$）广播不兼容，需用`keepdims=True`；\n",
    "6. 3阶张量求和形状：轴0求和→$[3,4]$，轴1求和→$[2,4]$，轴2求和→$[2,3]$；\n",
    "7. 高阶张量范数：`torch.norm`计算所有元素平方和的平方根（等价于将张量展平为向量后的$L_2$范数）。# 线性代数核心知识总结\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714b8089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
